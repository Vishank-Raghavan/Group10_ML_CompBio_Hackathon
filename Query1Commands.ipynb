{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpYk4dHcJyxN"
   },
   "source": [
    "# Example script for Hackathon\n",
    "\n",
    "Within each cycle of active learning, you can:\n",
    "\n",
    "1. Collect training data (original training data + your query data).\n",
    "\n",
    "2. Train a prediction model to predict the DMS_score for each mutant (e.g., M0A).\n",
    "\n",
    "3. Use the trained model to predict the score for all mutant in the test set.\n",
    "\n",
    "4. Select query mutants for next round based on certain criteria. You may want to make sure you don't query the same mutant twice as you only have a limited chances of making queries in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "PDuz5mihLReY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 28 21:23:33 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA A100-PCIE-40GB          On  |   00000000:25:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0             46W /  250W |       1MiB /  40960MiB |      0%      Default |\r\n",
      "|                                         |                        |             Disabled |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "from copy import deepcopy\n",
    "#!pip install pandas\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "## Added Packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9WI5oTTKdIY"
   },
   "source": [
    "## 1. collect training data\n",
    "\n",
    "Upload `sequence.fasta`, `train.csv`, and `test.csv` to the current runtime:\n",
    "\n",
    "1. click the folder icon on the left\n",
    "\n",
    "2. click the upload icon and upload the files to the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "Tj-TUAeZLEUz",
    "outputId": "88a181fb-fa9f-4954-caab-f7342a9d0b97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLREKMRRRLESGDKWFSLEFFPPRTAEGAVNLISRFDRMAAGGPLYIDVTWHPAGDPGSDKETSSMMIASTAVNYCGLETILHMTCCRQRLEEITGHLHKAKQLGLKNIMALRGDPIGDQWEEEEGGFNYAVDLVKHIRSEFGDYFDICVAGYPKGHPEAGSFEADLKHLKEKVSAGADFIITQLFFEADTFFRFVKACTDMGITCPIVPGIFPIQGYHSLRQLVKLSKLEVPQEIKDVIEPIKDNDAAIRNYGIELAVSLCQELLASGLVPGLHFYTLNREMATTEVLKRLGMWTEDPRRPLPWALSAHPKRREEDVRPIFWASRPKSYIYRTQEWDEFPNGRWGNSSSPAFGELKDYYLFYLKSKSPKEELLKMWGEELTSEESVFEVFVLYLSGEPNRNGHKVTCLPWNDEPLAAETSLLKEELLRVNRQGILTINSQPNINGKPSSDPIVGWGPSGGYVFQKAYLEFFTSRETAEALLQVLKKYELRVNYHLVNVKGENITNAPELQPNAVTWGIFPGREIIQPTVVDPVSFMFWKDEAFALWIERWGKLYEEESPSRTIIQYIHDNYFLVNLVDNDFPLDNCLWQVVEDTLELLNRPTQNARETEAP'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sequence.fasta', 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "sequence_wt = data[1].strip()\n",
    "sequence_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dewLzhLYMUSJ",
    "outputId": "f2c11453-a976-4778-f30d-57321d41e5d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "N-tkTaqtK9AD"
   },
   "outputs": [],
   "source": [
    "def get_mutated_sequence(mut, sequence_wt):\n",
    "    wt, pos, mt = mut[0], int(mut[1:-1]), mut[-1]\n",
    "    sequence = deepcopy(sequence_wt)\n",
    "    return sequence[:pos]+mt+sequence[pos+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "bZH3YKNVyR-m",
    "outputId": "efff26ca-ec20-4bdc-9473-c3ebe01e996d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1D</td>\n",
       "      <td>MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1Y</td>\n",
       "      <td>MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1C</td>\n",
       "      <td>MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1A</td>\n",
       "      <td>MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V1E</td>\n",
       "      <td>MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11319</th>\n",
       "      <td>P655S</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>P655T</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>P655V</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11322</th>\n",
       "      <td>P655A</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>P655W</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11324 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mutant                                           sequence\n",
       "0        V1D  MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1        V1Y  MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "2        V1C  MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "3        V1A  MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "4        V1E  MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "...      ...                                                ...\n",
       "11319  P655S  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11320  P655T  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11321  P655V  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11322  P655A  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11323  P655W  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "\n",
       "[11324 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train['sequence'] = df_train.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1D</td>\n",
       "      <td>MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1Y</td>\n",
       "      <td>MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1C</td>\n",
       "      <td>MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1A</td>\n",
       "      <td>MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V1E</td>\n",
       "      <td>MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11319</th>\n",
       "      <td>P655S</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>P655T</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>P655V</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11322</th>\n",
       "      <td>P655A</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>P655W</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11324 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mutant                                           sequence\n",
       "0        V1D  MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1        V1Y  MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "2        V1C  MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "3        V1A  MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "4        V1E  MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "...      ...                                                ...\n",
       "11319  P655S  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11320  P655T  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11321  P655V  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11322  P655A  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11323  P655W  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "\n",
       "[11324 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "tqfIASlMLQe4",
    "outputId": "8a13634d-f9cd-4e3d-e7fb-efa11438e6a4"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test['sequence'] = df_test.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "B8hiStmfLXz6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>OriginalAA</th>\n",
       "      <th>AlteredAA</th>\n",
       "      <th>Position</th>\n",
       "      <th>changetotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2730</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>YM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2857</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>WM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2153</td>\n",
       "      <td>M</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>VM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3122</td>\n",
       "      <td>M</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>TM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2180</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>SM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>0.5922</td>\n",
       "      <td>R</td>\n",
       "      <td>N</td>\n",
       "      <td>334</td>\n",
       "      <td>NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>0.0412</td>\n",
       "      <td>R</td>\n",
       "      <td>H</td>\n",
       "      <td>334</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>0.4785</td>\n",
       "      <td>R</td>\n",
       "      <td>I</td>\n",
       "      <td>334</td>\n",
       "      <td>IR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>0.6796</td>\n",
       "      <td>R</td>\n",
       "      <td>K</td>\n",
       "      <td>334</td>\n",
       "      <td>KR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>0.3293</td>\n",
       "      <td>R</td>\n",
       "      <td>G</td>\n",
       "      <td>334</td>\n",
       "      <td>GR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score OriginalAA AlteredAA  Position changetotal\n",
       "0     0.2730          M         Y         0          YM\n",
       "1     0.2857          M         W         0          WM\n",
       "2     0.2153          M         V         0          VM\n",
       "3     0.3122          M         T         0          TM\n",
       "4     0.2180          M         S         0          SM\n",
       "...      ...        ...       ...       ...         ...\n",
       "1078  0.5922          R         N       334          NR\n",
       "1079  0.0412          R         H       334          HR\n",
       "1080  0.4785          R         I       334          IR\n",
       "1081  0.6796          R         K       334          KR\n",
       "1082  0.3293          R         G       334          GR\n",
       "\n",
       "[247 rows x 5 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: integrate the query data that you acquired each round into df_train\n",
    "def filter_df(input_df, check):\n",
    "    original_aa=[]\n",
    "    altered_aa=[]\n",
    "    position=[]\n",
    "    score=[]\n",
    "    changeTotal=[]\n",
    "    for i, row in enumerate(input_df['mutant']):\n",
    "        original_aa.append(list(input_df['mutant'][i])[0])\n",
    "        altered_aa.append(list(input_df['mutant'][i])[-1])\n",
    "        changeTotal.append(str(list(input_df['mutant'][i])[-1]) + str(list(input_df['mutant'][i])[0]))\n",
    "        position.append(int(''.join(list(input_df['mutant'][i])[1:-1])))\n",
    "        if check==\"train\":\n",
    "            score.append(input_df['DMS_score'][i])\n",
    "    if check==\"train\":\n",
    "        df = pd.DataFrame({'Score':score,'OriginalAA': original_aa, 'AlteredAA': altered_aa, 'Position': position, 'changetotal':changeTotal})\n",
    "    if check==\"test\":\n",
    "        df = pd.DataFrame({'OriginalAA': original_aa, 'AlteredAA': altered_aa, 'Position': position, 'changetotal':changeTotal})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_input=filter_df(df_train, \"train\")\n",
    "test_input=filter_df(df_test, \"test\")\n",
    "\n",
    "## Check positions\n",
    "\n",
    "## Check AA Change\n",
    "#set(train_input['changetotal']).difference(set(test_input['changetotal']))\n",
    "\n",
    "\n",
    "#\n",
    "dictOut=train_input['changetotal'].value_counts().to_dict()\n",
    "\n",
    "newDF=pd.DataFrame([dictOut]).T.reset_index()\n",
    "p1=newDF[newDF[0]==1][\"index\"]\n",
    "p2=newDF[newDF[0]==2][\"index\"]\n",
    "\n",
    "## Checking whether values in List\n",
    "BasePairChange=set(list(p2) + list(p1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=set(train_input['Position'])\n",
    "b=set(test_input['Position'])\n",
    "diffCheck=b.difference({0,\n",
    " 48,\n",
    " 87,\n",
    " 88,\n",
    " 89,\n",
    " 112,\n",
    " 126,\n",
    " 141,\n",
    " 148,\n",
    " 151,\n",
    " 152,\n",
    " 157,\n",
    " 158,\n",
    " 182,\n",
    " 185,\n",
    " 189,\n",
    " 191,\n",
    " 193,\n",
    " 195,\n",
    " 196,\n",
    " 216,\n",
    " 220,\n",
    " 221,\n",
    " 224,\n",
    " 227,\n",
    " 228,\n",
    " 242,\n",
    " 247,\n",
    " 250,\n",
    " 251,\n",
    " 252,\n",
    " 253,\n",
    " 254,\n",
    " 255,\n",
    " 258,\n",
    " 276,\n",
    " 289,\n",
    " 290,\n",
    " 292,\n",
    " 295,\n",
    " 296,\n",
    " 297,\n",
    " 298,\n",
    " 302,\n",
    " 304,\n",
    " 305,\n",
    " 308,\n",
    " 309,\n",
    " 311,\n",
    " 314,\n",
    " 315,\n",
    " 316,\n",
    " 318,\n",
    " 319,\n",
    " 320,\n",
    " 331,\n",
    " 334,\n",
    " 335,\n",
    " 336,\n",
    " 347})\n",
    "outConvertPos=[str(i) for i in diffCheck]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out=test_input[test_input['Position'].isin(diffCheck)]\n",
    "#test_input['Position'].isin(diffCheck)\n",
    "outFilter=test_input[test_input['changetotal'].isin(BasePairChange)]\n",
    "import random\n",
    "\n",
    "#random.sample(outFilter.index], 100)\n",
    "#print(random.sample([1,2,3,4,5], 5))\n",
    "outDF=random.sample(list(outFilter.index), 100)\n",
    "\n",
    "#outDF\n",
    "df = pd.DataFrame(outFilter, index=outDF)\n",
    "pd.DataFrame(df).to_csv(\"test_query.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 153, 154, 155, 156, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 186, 187, 188, 190, 192, 194, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 222, 223, 225, 226, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 248, 249, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 291, 293, 294, 299, 300, 301, 303, 306, 307, 310, 312, 313, 317, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 333, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655]\n"
     ]
    }
   ],
   "source": [
    "TestUnique=list(set(test_input['Position']))\n",
    "TrainUnique=list(set(train_input['Position']))\n",
    "result = [x for x in TestUnique if x not in TrainUnique]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 48,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 112,\n",
       " 126,\n",
       " 141,\n",
       " 148,\n",
       " 151,\n",
       " 152,\n",
       " 157,\n",
       " 158,\n",
       " 182,\n",
       " 185,\n",
       " 189,\n",
       " 191,\n",
       " 193,\n",
       " 195,\n",
       " 196,\n",
       " 216,\n",
       " 220,\n",
       " 221,\n",
       " 224,\n",
       " 227,\n",
       " 228,\n",
       " 242,\n",
       " 247,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 258,\n",
       " 276,\n",
       " 289,\n",
       " 290,\n",
       " 292,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 302,\n",
       " 304,\n",
       " 305,\n",
       " 308,\n",
       " 309,\n",
       " 311,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 331,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 347}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = {1, 2, 3, 4, 5}\n",
    "B = {3, 4, 5, 6, 7}\n",
    "C = {5, 6, 7, 8, 9}\n",
    "\n",
    "res = A.difference(B, C)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cty7BGBLdgp"
   },
   "source": [
    "## 2. Train a prediction model\n",
    "\n",
    "Here, we provided a linear regression model and used one-hot encoding to encode each variant. You would need to build your own model to achieve better performances.\n",
    "\n",
    "Hint: you can perform cross-validation on the training set to evaluate your predictor before making predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "N4rvH-HzOmN_"
   },
   "outputs": [],
   "source": [
    "'''hyperparameters'''\n",
    "\n",
    "seq_length = 656\n",
    "seed = 0 # seed for splitting the validation set\n",
    "val_ratio = 0.2 # proportion of validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bg2fQKEKLsTJ"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df, istrain=True):\n",
    "\n",
    "        alphabet = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "        map_a2i = {j:i for i,j in enumerate(alphabet)}\n",
    "        map_i2a = {i:j for i,j in enumerate(alphabet)}\n",
    "\n",
    "        self.df = df\n",
    "\n",
    "        self.num_samples = len(self.df)\n",
    "        self.seq_length = len(self.df.sequence.values[0])\n",
    "        self.num_channels = 20\n",
    "\n",
    "        # TODO: replace one-hot encodings with your own encodings\n",
    "        self.encodings = np.zeros((self.num_samples, self.num_channels, self.seq_length)).astype(np.float32)\n",
    "        self.targets = np.zeros(self.num_samples).astype(np.float32)\n",
    "\n",
    "        if istrain:\n",
    "            for it, (seq,target) in enumerate(self.df[['sequence', 'DMS_score']].values):\n",
    "                for i,aa in enumerate(seq):\n",
    "                    self.encodings[it,map_a2i[aa], i  + (20*i)] = 1\n",
    "                self.targets[it] = target\n",
    "\n",
    "            self.encodings = self.encodings.astype(np.float32)\n",
    "            self.targets = self.targets.astype(np.float32)\n",
    "        else:\n",
    "            for it, seq in enumerate(self.df['sequence'].values):\n",
    "                for i,aa in enumerate(seq):\n",
    "                    self.encodings[it,map_a2i[aa],i  + (20*i)] = 1\n",
    "            self.encodings = self.encodings.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.encodings[idx]), torch.tensor(self.targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UERT_WBPOgOk"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 672 is out of bounds for axis 2 with size 656",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mProteinDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m ProteinDataset(df_test, istrain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# split validation set\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m, in \u001b[0;36mProteinDataset.__init__\u001b[0;34m(self, df, istrain)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it, (seq,target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDMS_score\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,aa \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seq):\n\u001b[0;32m---> 21\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodings[it,map_a2i[aa], i  \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m20\u001b[39m\u001b[38;5;241m*\u001b[39mi)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[it] \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodings\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 672 is out of bounds for axis 2 with size 656"
     ]
    }
   ],
   "source": [
    "train_dataset = ProteinDataset(df_train)\n",
    "test_dataset = ProteinDataset(df_test, istrain=False)\n",
    "\n",
    "# split validation set\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=val_ratio, random_state=seed, shuffle=True)\n",
    "\n",
    "# TODO: revise according to your own model\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class initial_model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(initial_model, self).__init__()\n",
    "        self.fc1=nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2=nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x) \n",
    "        return x\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device='cuda:0'):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequence, fitness in dataloader:\n",
    "            input_values = sequence.to(device)\n",
    "            label_values = fitness.to(device).view(-1)\n",
    "\n",
    "            outputs = model(input_values)\n",
    "            loss = criterion(outputs, label_values)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "    \n",
    "def train(model, dataloader_train, dataloader_val, epochs=200, lr=0.002, patience=50, device='cuda:0'):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_ckpt = model.state_dict()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for sequence, fitness in dataloader_train:\n",
    "            input_values = sequence.to(device)\n",
    "            label_values = fitness.to(device).view(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_values)\n",
    "            loss = criterion(outputs, label_values)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_loss = evaluate(model, dataloader_val, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={total_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_ckpt = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    return best_ckpt\n",
    "\n",
    "# Initialize model\n",
    "input_dim = 656\n",
    "hidden_dim = 32\n",
    "output_dim = 1\n",
    "\n",
    "model = initial_model(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Train the model\n",
    "best_ckpt = train(model, dataloader_train=train_loader, dataloader_val=val_loader, epochs=100, lr=1e-2, patience=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jwv3JLn0OphU"
   },
   "outputs": [],
   "source": [
    "# TODO: build your own prediction model to replace linear regression\n",
    "# Hint: don't forget to use the validation set: you can either integrate the validation data into the training set or use it separately for early stopping\n",
    "\n",
    "X_train, y_train = next(iter(train_loader))\n",
    "\n",
    "regressor = LinearRegression()\n",
    "#regressor=RandomForestRegressor()\n",
    "\n",
    "#nn.Sequential()\n",
    "\n",
    "regressor.fit(X_train.view(X_train.size(0), -1).numpy(), y_train.numpy())\n",
    "\n",
    "X_test, _ = next(iter(test_loader))\n",
    "y_test_pred = regressor.predict(X_test.view(X_test.size(0), -1).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "GzinalQwQhVM",
    "outputId": "e36aec40-e283-47c8-8287-ec5e80f8026d"
   },
   "outputs": [],
   "source": [
    "df_test['DMS_score_predicted'] = y_test_pred\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz92uKHzg0w_"
   },
   "outputs": [],
   "source": [
    "df_test[['mutant', 'DMS_score_predicted']].to_csv('test_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNX78OGrRZ46"
   },
   "source": [
    "## 3. Select query for next round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "SBXWtW8zQpxG",
    "outputId": "89730bec-feaf-4187-d415-ef786dd56e61"
   },
   "outputs": [],
   "source": [
    "df_test.sort_values('DMS_score_predicted', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k46Og-FBiKyu",
    "outputId": "f75d32e4-5d52-49b8-bdbb-7e7da1645e35"
   },
   "outputs": [],
   "source": [
    "# Example: randomly select 100 test variants to be queried.\n",
    "# Note: random selection may not be a good strategy\n",
    "# TODO: select query mutants for the next round based on your own criteria\n",
    "\n",
    "querys = np.random.choice(df_test.mutant.values, size=100, replace=False)\n",
    "querys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltHYwv3Pi0lx"
   },
   "outputs": [],
   "source": [
    "with open('query.txt', 'w') as f:\n",
    "    for mutant in querys:\n",
    "        f.write(mutant+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsS5lPPIM8k5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
